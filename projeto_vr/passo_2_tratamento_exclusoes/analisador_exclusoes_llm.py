#!/usr/bin/env python3
# analisador_exclusoes_llm.py - Usa LLM para analisar dados do Passo 1 e identificar exclus√µes por cargo

import glob
import json
import os
import re
import sys
from datetime import datetime
from pathlib import Path

try:
    import google.generativeai as genai
except ImportError:
    genai = None

# Importar configura√ß√µes da raiz do projeto
sys.path.append(str(Path(__file__).parent.parent.parent))

# Importar configura√ß√µes da raiz do projeto
from config import GOOGLE_API_KEY, NOME_MODELO_LLM

# Importar sistema de logging
sys.path.append(str(Path(__file__).parent.parent.parent))
from utils.logging_config import log_fim_passo, log_inicio_passo, setup_logging

logger = setup_logging()

# Importar dados consolidados (passo 1)
sys.path.append(str(Path(__file__).parent.parent / "passo_1_leitura_validacao"))
from consolidador_json import obter_dados_consolidados


class AnalisadorExclusions:
    """Analisador que usa LLM para identificar, por CARGO, se deve excluir/manter e o motivo."""

    def __init__(self):
        # Inicializa√ß√£o obrigat√≥ria do cliente LLM
        self.genai = genai
        self.model = None
        if self.genai is not None:
            try:
                logger.info(f"üîß Configurando cliente LLM: {NOME_MODELO_LLM}")
                self.genai.configure(api_key=GOOGLE_API_KEY)
                self.model = self.genai.GenerativeModel(NOME_MODELO_LLM)
                logger.info("‚úÖ Cliente LLM inicializado com sucesso")
            except Exception as e:
                raise RuntimeError(
                    f"‚ùå ERRO CR√çTICO: N√£o foi poss√≠vel inicializar o cliente LLM: {e}"
                )
        else:
            raise RuntimeError(
                "‚ùå ERRO CR√çTICO: Pacote google.generativeai n√£o encontrado. Instale com: pip install google-generativeai"
            )

    def _carregar_ccts(self, caminho_convencoes: str) -> dict:
        """Carrega informa√ß√µes das CCTs dispon√≠veis."""
        ccts_info = {}

        try:
            # Buscar arquivos de CCT na pasta
            caminho_convencoes = Path(caminho_convencoes)
            if not caminho_convencoes.exists():
                logger.warning(
                    f"‚ö†Ô∏è Pasta de conven√ß√µes n√£o encontrada: {caminho_convencoes}"
                )
                return {}

            arquivos_cct = list(caminho_convencoes.glob("*.pdf"))
            logger.info(f"üìã Encontrados {len(arquivos_cct)} arquivos de CCT")

            for arquivo in arquivos_cct:
                nome = arquivo.stem
                # Identificar o estado baseado no nome do arquivo
                estado = "S√£o Paulo"  # padr√£o
                if "rio grande do sul" in nome.lower():
                    estado = "Rio Grande do Sul"
                elif "paran√°" in nome.lower() or "parana" in nome.lower():
                    estado = "Paran√°"
                elif "rio de janeiro" in nome.lower():
                    estado = "Rio de Janeiro"
                elif "s√£o paulo" in nome.lower() or "sao paulo" in nome.lower():
                    estado = "S√£o Paulo"

                ccts_info[estado] = {
                    "arquivo": nome,
                    "caminho": str(arquivo),
                    "descricao": f"CCT {estado}",
                }

            logger.info(
                f"‚úÖ {len(ccts_info)} CCTs identificadas: {list(ccts_info.keys())}"
            )
            return ccts_info

        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar CCTs: {e}")
            return {}

    def analisar_dados_passo1(
        self, caminho_colaboradores: str, caminho_configuracoes: str
    ) -> dict:
        """Analisa os dados consolidados do Passo 1 usando LLM e retorna o mapeamento por cargo.

        Retorna um dicion√°rio com chaves: timestamp_analise, dados_origem, analise_llm, resposta_completa_llm
        """
        log_inicio_passo(
            "PASSO 2",
            "An√°lise LLM - Exclus√µes conforme Regras Oficiais (Diretores/Estagi√°rios/Aprendizes)",
            logger,
        )
        logger.info(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("üìÇ Carregando dados em mem√≥ria")

        # 1. Obter dados consolidados do Passo 1
        dados = obter_dados_consolidados(caminho_colaboradores, caminho_configuracoes)

        return self._executar_analise_com_dados(dados)

    def analisar_com_dados_memoria(self, dados_consolidados: dict) -> dict:
        """Analisa dados j√° consolidados que est√£o em mem√≥ria.

        Args:
            dados_consolidados: Dicion√°rio com dados j√° consolidados do Passo 1

        Returns:
            Dicion√°rio com resultado da an√°lise LLM
        """
        log_inicio_passo(
            "PASSO 2",
            "An√°lise LLM - Exclus√µes conforme Regras Oficiais (Diretores/Estagi√°rios/Aprendizes)",
            logger,
        )
        logger.info(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("üìä Usando dados em mem√≥ria (otimizado)")
        logger.info(
            "üí° Dica: Para m√°xima efici√™ncia, use o arquivo agrupamentos_consolidados.json"
        )

        return self._executar_analise_com_dados(dados_consolidados)

    def analisar_com_agrupamentos_json(self, caminho_agrupamentos: str) -> dict:
        """Analisa dados do arquivo agrupamentos_consolidados.json.

        Args:
            caminho_agrupamentos: Caminho para o arquivo agrupamentos_consolidados.json

        Returns:
            Dicion√°rio com resultado da an√°lise LLM
        """
        log_inicio_passo(
            "PASSO 2",
            "An√°lise LLM - Exclus√µes conforme Regras Oficiais (Diretores/Estagi√°rios/Aprendizes)",
            logger,
        )
        logger.info(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("üìÇ Carregando dados do arquivo de agrupamentos")

        try:
            with open(caminho_agrupamentos, "r", encoding="utf-8") as f:
                agrupamentos = json.load(f)

            logger.info(f"‚úÖ Arquivo carregado: {caminho_agrupamentos}")
            logger.info(
                f"üéØ {len(agrupamentos.get('cargos', []))} cargos √∫nicos encontrados"
            )
            logger.info(
                f"üìä {len(agrupamentos.get('status', []))} status √∫nicos encontrados"
            )
            logger.info(
                f"üîç {len(agrupamentos.get('situacoes', []))} situa√ß√µes √∫nicas encontradas"
            )

            # Carregar CCTs
            caminho_projeto = Path(caminho_agrupamentos).parent.parent
            caminho_convencoes = caminho_projeto / "input_data" / "convencoes"
            ccts_info = self._carregar_ccts(str(caminho_convencoes))

            return self._executar_analise_com_agrupamentos(agrupamentos, ccts_info)

        except FileNotFoundError:
            logger.error(f"‚ùå Arquivo n√£o encontrado: {caminho_agrupamentos}")
            return {"erro": f"Arquivo n√£o encontrado: {caminho_agrupamentos}"}
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erro ao decodificar JSON: {e}")
            return {"erro": f"Erro ao decodificar JSON: {e}"}
        except Exception as e:
            logger.error(f"‚ùå Erro inesperado: {e}")
            return {"erro": f"Erro inesperado: {e}"}

    def _executar_analise_com_agrupamentos(
        self, agrupamentos: dict, ccts_info: dict = None
    ) -> dict:
        """M√©todo privado que executa a an√°lise LLM usando dados de agrupamentos."""

        # Extrair listas dos agrupamentos
        cargos_unicos = set(agrupamentos.get("cargos", []))
        status_unicos = set(agrupamentos.get("status", []))
        situacoes_unicas = set(agrupamentos.get("situacoes", []))

        logger.info(f"üîç An√°lise de {len(cargos_unicos)} cargos √∫nicos identificados")
        logger.info(f"üìä Status encontrados: {', '.join(sorted(status_unicos))}")
        logger.info(f"üéØ Situa√ß√µes encontradas: {', '.join(sorted(situacoes_unicas))}")

        # Criar dados fict√≠cios para an√°lise (necess√°rio para o prompt)
        dados_para_analise = {
            "colaboradores": {},
            "resumo_agrupamentos": {
                "cargos_unicos": list(cargos_unicos),
                "status_unicos": list(status_unicos),
                "situacoes_unicas": list(situacoes_unicas),
            },
            "ccts_info": ccts_info or {},
        }

        return self._executar_analise_com_dados(dados_para_analise)

    def _executar_analise_com_dados(self, dados: dict) -> dict:
        """M√©todo privado que executa a an√°lise LLM usando os dados consolidados."""

        # 1. Extrair cargos √∫nicos dos colaboradores
        colaboradores = dados.get("colaboradores", {})
        cargos_unicos = set()

        for colaborador in colaboradores.values():
            cargo = colaborador.get("cargo", "").strip()
            if cargo:
                cargos_unicos.add(cargo)

        # Se n√£o h√° colaboradores, usar os agrupamentos
        if not cargos_unicos and "resumo_agrupamentos" in dados:
            cargos_unicos = set(dados["resumo_agrupamentos"].get("cargos_unicos", []))

        cargos_lista = sorted(list(cargos_unicos))
        logger.info(f"üéØ {len(cargos_lista)} cargos √∫nicos para an√°lise")

        # 2. Preparar prompt para LLM
        logger.info("ü§ñ Enviando dados para an√°lise pela LLM")
        logger.info(f"üöÄ Enviando prompt para {NOME_MODELO_LLM}")

        prompt = self._construir_prompt_analise(cargos_lista, dados)

        # 3. Executar consulta LLM
        try:
            response = self.model.generate_content(prompt)
            logger.info("‚úÖ Resposta recebida da LLM")

            # 4. Processar resposta
            resposta_texto = response.text

            # 5. Tentar extrair JSON da resposta
            try:
                # Extrair JSON usando regex (caso a LLM adicione texto extra)
                json_match = re.search(r"\{.*\}", resposta_texto, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                    analise_llm = json.loads(json_str)
                else:
                    # Se n√£o encontrar JSON, tentar parsear a resposta completa
                    analise_llm = json.loads(resposta_texto)

            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è Erro ao parsear JSON da LLM: {e}")
                # Criar estrutura padr√£o em caso de erro
                analise_llm = {
                    "timestamp_analise": datetime.now().isoformat(),
                    "erro_parsing": str(e),
                    "resposta_bruta": resposta_texto,
                    "cargos_para_excluir": [],
                    "status_para_excluir": [],
                    "situacoes_para_excluir": [],
                    "cargos_para_manter": cargos_lista,
                }

            logger.info("‚úÖ An√°lise JSON parseada com sucesso")

            # Preparar estat√≠sticas para o log
            estatisticas = {
                "total_cargos_analisados": len(cargos_lista),
                "cargos_para_excluir": len(analise_llm.get("cargos_para_excluir", [])),
                "status_para_excluir": len(analise_llm.get("status_para_excluir", [])),
                "situacoes_para_excluir": len(
                    analise_llm.get("situacoes_para_excluir", [])
                ),
                "cargos_para_manter": len(analise_llm.get("cargos_para_manter", [])),
            }

            # 6. Estruturar resultado final
            resultado = {
                "timestamp_analise": datetime.now().isoformat(),
                "dados_origem": {
                    "total_cargos_analisados": len(cargos_lista),
                    "cargos_lista": cargos_lista,
                },
                "analise_llm": analise_llm,
                "resposta_completa_llm": resposta_texto,
            }

            log_fim_passo(
                "PASSO 2",
                f"An√°lise LLM conclu√≠da para {len(cargos_lista)} cargos",
                estatisticas,
                logger,
            )

            # Salvar resultado para debug/an√°lise
            try:
                import os

                output_dir = Path(__file__).parent.parent.parent / "output"
                resultado_path = output_dir / "passo_2-resultado_llm.json"

                with open(resultado_path, "w", encoding="utf-8") as f:
                    json.dump(resultado, f, indent=2, ensure_ascii=False)
                logger.info(f"üìÑ Resultado salvo para an√°lise: {resultado_path}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel salvar resultado: {e}")

            return resultado

        except Exception as e:
            logger.error(f"‚ùå Erro ao executar an√°lise LLM: {e}")
            return {
                "erro": str(e),
                "timestamp_erro": datetime.now().isoformat(),
                "cargos_analisados": cargos_lista,
            }

    def _construir_prompt_analise(self, cargos_lista: list, dados: dict) -> str:
        """Constr√≥i o prompt para an√°lise LLM dos cargos."""

        # Extrair informa√ß√µes das CCTs
        ccts_info = dados.get("ccts_info", {})
        ccts_text = ""
        if ccts_info:
            ccts_text = f"\nCCTs DISPON√çVEIS:\n"
            for estado, info in ccts_info.items():
                ccts_text += f"- {estado}: {info.get('descricao', 'CCT dispon√≠vel')}\n"
            ccts_text += "\nCONSIDERE: As CCTs podem conter regras espec√≠ficas sobre exclus√£o de cargos de gest√£o do Vale-Refei√ß√£o.\n"

        prompt = f"""
Analise OBRIGATORIAMENTE e determine exclus√µes para Vale-Refei√ß√£o conforme regras oficiais.

REGRAS OFICIAIS DE EXCLUS√ÉO:

CARGOS PARA EXCLUIR (OBRIGAT√ìRIO):
- DIRETORES: Qualquer cargo que contenha "DIRETOR", "CEO", "PRESIDENTE", "VICE-PRESIDENTE"
- GEST√ÉO: Cargos de GERENTE e COORDENADOR com fun√ß√µes administrativas, financeiras, estrat√©gicas
- Estagi√°rios e Aprendizes (Lei 11.788/2008 e Lei 10.097/2000)

CRIT√âRIO JUR√çDICO PARA GERENTES E COORDENADORES:
- S√£o considerados "alta gest√£o" quando exercem fun√ß√µes de dire√ß√£o, coordena√ß√£o administrativa
- Cargos que coordenam equipes, projetos estrat√©gicos ou departamentos inteiros
- Fun√ß√µes com autonomia decis√≥ria em recursos humanos, finan√ßas ou opera√ß√µes cr√≠ticas
- Conforme Lei 6.321/76 e interpreta√ß√£o jurisprudencial dos TSTs

STATUS PARA EXCLUIR:
- "aprendiz", "est√°gio", "exterior"  

SITUA√á√ïES PARA EXCLUIR:
- "Licen√ßa Maternidade", "Aux√≠lio Doen√ßa", "n√£o recebe VR"
- N√ÉO EXCLUIR: "Atestado" (deve ser tratado proporcionalmente, n√£o exclu√≠do totalmente)

{ccts_text}

INSTRU√á√ïES CR√çTICAS:
1. ANALISAR RIGOROSAMENTE TODOS OS CARGOS na lista completa
2. IDENTIFICAR obrigatoriamente qualquer cargo contendo: DIRETOR (100% exclus√£o)
3. AVALIAR COORDENADORES e GERENTES com base na fun√ß√£o (n√£o apenas t√≠tulo)
4. INCLUIR justificativa jur√≠dica para cada exclus√£o de cargo de gest√£o
5. CONSIDERAR que CCTs podem permitir exclus√£o de cargos administrativos/gest√£o

DADOS PARA AN√ÅLISE:
CARGOS COMPLETOS: {', '.join(cargos_lista)}
STATUS: {', '.join(dados.get('resumo_agrupamentos', {}).get('status_unicos', []))}
SITUA√á√ïES: {', '.join(dados.get('resumo_agrupamentos', {}).get('situacoes_unicas', []))}

RESPONDA APENAS COM JSON V√ÅLIDO - JUSTIFIQUE CADA EXCLUS√ÉO:
{{
  "cargos_para_excluir": [
    {{"cargo": "NOME_EXATO_DO_CARGO", "motivo": "Cargo de alta gest√£o com autonomia decis√≥ria", "regra_aplicada": "Lei 6.321/76 - Alta Gest√£o", "fundamento_juridico": "Fun√ß√£o administrativa/estrat√©gica"}}
  ],
  "status_para_excluir": [
    {{"status": "NOME", "motivo": "Status de exclus√£o obrigat√≥ria", "regra_aplicada": "Status"}}
  ],
  "situacoes_para_excluir": [
    {{"situacao": "NOME", "motivo": "Situa√ß√£o de afastamento", "regra_aplicada": "Situa√ß√£o"}}
  ],
  "resumo": {{
    "total_cargos_excluir": 0,
    "total_status_excluir": 0,
    "total_situacoes_excluir": 0,
    "criterio_principal": "Regras oficiais do projeto"
  }}
}}"""
        return prompt


def main():
    """Fun√ß√£o principal para teste do analisador."""

    logger.info("üß™ TESTE DO ANALISADOR DE EXCLUS√ïES LLM")

    # Caminhos para os arquivos de teste
    caminho_colaboradores = (
        Path(__file__).parent.parent.parent / "input_data" / "colaboradores"
    )
    caminho_configuracoes = (
        Path(__file__).parent.parent.parent / "input_data" / "configuracoes"
    )

    if not caminho_colaboradores.exists():
        logger.error(f"‚ùå Diret√≥rio n√£o encontrado: {caminho_colaboradores}")
        return

    # Executar an√°lise
    analisador = AnalisadorExclusions()
    resultado = analisador.analisar_dados_passo1(
        str(caminho_colaboradores), str(caminho_configuracoes)
    )

    # Exibir resultado
    logger.info("üìã RESULTADO DA AN√ÅLISE:")
    logger.info(
        f"üéØ Total de cargos analisados: {resultado.get('dados_origem', {}).get('total_cargos_analisados', 'N/A')}"
    )

    if "analise_llm" in resultado:
        analise = resultado["analise_llm"]
        logger.info(
            f"‚ùå Cargos para excluir: {len(analise.get('cargos_para_excluir', []))}"
        )
        logger.info(
            f"‚úÖ Cargos para manter: {len(analise.get('cargos_para_manter', []))}"
        )

        # Mostrar alguns exemplos
        if analise.get("cargos_para_excluir"):
            logger.info("üî¥ Exemplos de exclus√µes:")
            for cargo in analise["cargos_para_excluir"][:3]:
                logger.info(
                    f"  ‚Ä¢ {cargo.get('cargo', 'N/A')}: {cargo.get('motivo', 'N/A')}"
                )


if __name__ == "__main__":
    main()
